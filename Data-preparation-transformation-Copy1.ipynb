{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import isnull, isnan\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName('Preparation').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "age= spark.read.csv('age_gender_bkts.csv',header=True,inferSchema=True)\n",
    "country= spark.read.csv('countries.csv',header=True,inferSchema=True)\n",
    "session= spark.read.csv('sessions.csv',header=True,inferSchema=True)\n",
    "train_users = spark.read.csv('train_users_2.csv',header=True,inferSchema=True)\n",
    "test_users = spark.read.csv('test_users.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('country_destination', 'string'),\n",
       " ('distance_km', 'double'),\n",
       " ('destination_km2', 'double'),\n",
       " ('destination_language ', 'string'),\n",
       " ('language_levenshtein_distance', 'double')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age.drop('year').dtypes\n",
    "country.drop('lat_destination','lng_destination').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+---------------+\n",
      "|              action|action_type|       action_detail|    device_type|\n",
      "+--------------------+-----------+--------------------+---------------+\n",
      "|              lookup|        NaN|                 NaN|Windows Desktop|\n",
      "|      search_results|      click| view_search_results|Windows Desktop|\n",
      "|              lookup|        NaN|                 NaN|Windows Desktop|\n",
      "|      search_results|      click| view_search_results|Windows Desktop|\n",
      "|              lookup|        NaN|                 NaN|Windows Desktop|\n",
      "|      search_results|      click| view_search_results|Windows Desktop|\n",
      "|              lookup|        NaN|                 NaN|Windows Desktop|\n",
      "|         personalize|       data|wishlist_content_...|Windows Desktop|\n",
      "|               index|       view| view_search_results|Windows Desktop|\n",
      "|              lookup|        NaN|                 NaN|Windows Desktop|\n",
      "|      search_results|      click| view_search_results|Windows Desktop|\n",
      "|              lookup|        NaN|                 NaN|Windows Desktop|\n",
      "|         personalize|       data|wishlist_content_...|Windows Desktop|\n",
      "|               index|       view| view_search_results|Windows Desktop|\n",
      "|    similar_listings|       data|    similar_listings|Windows Desktop|\n",
      "|ajax_refresh_subt...|      click|change_trip_chara...|Windows Desktop|\n",
      "|    similar_listings|       data|    similar_listings|Windows Desktop|\n",
      "|ajax_refresh_subt...|      click|change_trip_chara...|Windows Desktop|\n",
      "|                show|        NaN|                 NaN|Windows Desktop|\n",
      "|         personalize|       data|wishlist_content_...|Windows Desktop|\n",
      "+--------------------+-----------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------+\n",
      "|secs_elapsed|\n",
      "+------------+\n",
      "|       319.0|\n",
      "|     67753.0|\n",
      "|       301.0|\n",
      "|     22141.0|\n",
      "|       435.0|\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.select(\"action\",\"action_type\",\"action_detail\",\"device_type\").na.fill(\"NaN\").show()\n",
    "session.select(\"secs_elapsed\").na.fill(19402).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|  MALE|13769|\n",
      "|FEMALE|14483|\n",
      "|   NaN|33844|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_users = train_users.withColumn('gender', regexp_replace('gender', 'OTHER', 'NaN'))\n",
    "train_users = train_users.withColumn('gender', regexp_replace('gender', '-unknown-', 'NaN'))\n",
    "test_users = test_users.withColumn('gender', regexp_replace('gender', 'OTHER', 'NaN'))\n",
    "test_users = test_users.withColumn('gender', regexp_replace('gender', '-unknown-', 'NaN'))\n",
    "test_users.groupBy('gender').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               age|\n",
      "+-------+------------------+\n",
      "|  count|            125461|\n",
      "|   mean| 49.66833517985669|\n",
      "| stddev|155.66661183021571|\n",
      "|    min|               1.0|\n",
      "|    max|              99.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_users= train_users.withColumn('age', regexp_replace('age', 'age>114', '-1'))\n",
    "train_users= train_users.withColumn('age', regexp_replace('age', 'age<18', '-1'))\n",
    "train_users.select('age').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_users= train_users.withColumn('date_first_active', train_users[\"timestamp_first_active\"] / 1000000)\n",
    "train_users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users.date_account_created= train_users.date_account_created.astype('date')\n",
    "train_users.date_first_booking= train_users.date_first_booking.astype('date')\n",
    "#train_users.date_first_active = train_users.date_first_active.astype('date')\n",
    "train_users.age= train_users.age.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, date_account_created: timestamp, timestamp_first_active: bigint, date_first_booking: string, gender: string, age: double, signup_method: string, signup_flow: int, language: string, affiliate_channel: string, affiliate_provider: string, first_affiliate_tracked: string, signup_app: string, first_device_type: string, first_browser: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_users.na.fill(\"NaN\")\n",
    "test_users.na.fill(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('date_account_created', 'timestamp'),\n",
       " ('timestamp_first_active', 'bigint'),\n",
       " ('date_first_booking', 'timestamp'),\n",
       " ('gender', 'string'),\n",
       " ('age', 'string'),\n",
       " ('signup_method', 'string'),\n",
       " ('signup_flow', 'int'),\n",
       " ('language', 'string'),\n",
       " ('affiliate_channel', 'string'),\n",
       " ('affiliate_provider', 'string'),\n",
       " ('first_affiliate_tracked', 'string'),\n",
       " ('signup_app', 'string'),\n",
       " ('first_device_type', 'string'),\n",
       " ('first_browser', 'string'),\n",
       " ('country_destination', 'string'),\n",
       " ('user_id', 'string'),\n",
       " ('sum(secs_elapsed)', 'double')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_new=session.groupBy(\"user_id\").sum(\"secs_elapsed\")\n",
    "new_train=train_users.join(session_new,train_users.id== session_new.user_id)\n",
    "new_train.drop('user_id')\n",
    "new_train.dtypes\n",
    "#new_train.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test=test_users.join(session_new,test_users.id== session_new.user_id)\n",
    "new_test=new_test.drop('user_id')\n",
    "#new_test.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection\n",
    "Delete the timestamp_first_active|date_first_booking\\id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- signup_method: string (nullable = true)\n",
      " |-- signup_flow: integer (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- affiliate_channel: string (nullable = true)\n",
      " |-- affiliate_provider: string (nullable = true)\n",
      " |-- first_affiliate_tracked: string (nullable = true)\n",
      " |-- signup_app: string (nullable = true)\n",
      " |-- first_device_type: string (nullable = true)\n",
      " |-- first_browser: string (nullable = true)\n",
      " |-- sum(secs_elapsed): double (nullable = true)\n",
      " |-- country_destination: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_train=new_train.select('gender','age','signup_method','signup_flow','language','affiliate_channel','affiliate_provider','first_affiliate_tracked','signup_app','first_device_type','first_browser','sum(secs_elapsed)','country_destination')\n",
    "cols=new_train.columns\n",
    "new_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant packages.\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer)\n",
    "\n",
    "# First create a string indexer which converts every string into a number, such as male = 0 and female = 1.\n",
    "# A number will be assigned to every category in the column.\n",
    "gender_indexer=StringIndexer(inputCol='gender',outputCol='genderIndex')\n",
    "signup_method_indexer=StringIndexer(inputCol='signup_method',outputCol='signup_methodIndex')\n",
    "language_indexer=StringIndexer(inputCol='language',outputCol='languageIndex')\n",
    "affiliate_channel_indexer=StringIndexer(inputCol='affiliate_channel',outputCol='affiliate_channelIndex')\n",
    "affiliate_provider_indexer=StringIndexer(inputCol='affiliate_provider',outputCol='affiliate_providerIndex')\n",
    "first_affiliate_tracked_indexer=StringIndexer(inputCol='first_affiliate_tracked',outputCol='first_affiliate_trackedIndex')\n",
    "signup_app_indexer=StringIndexer(inputCol='signup_app',outputCol='signup_appIndex')\n",
    "first_device_type_indexer=StringIndexer(inputCol='first_device_type',outputCol='first_device_typeIndex')\n",
    "first_browser_indexer=StringIndexer(inputCol='first_browser',outputCol='first_browserIndex')\n",
    "country_destination_indexer=StringIndexer(inputCol='country_destination',outputCol='country_destinationIndex')\n",
    "# Now we can one hot encode these numbers. This converts the various outputs into a single vector.\n",
    "# Multiple columns are collapsed into one. \n",
    "# This makes it easier to process when you have multiple classes.\n",
    "gender_encoder = OneHotEncoder(inputCol='genderIndex',outputCol='genderVec')\n",
    "signup_method_encoder = OneHotEncoder(inputCol='signup_methodIndex',outputCol='signup_methodVec')\n",
    "language_encoder = OneHotEncoder(inputCol='languageIndex',outputCol='languageVec')\n",
    "affiliate_channel_encoder = OneHotEncoder(inputCol='affiliate_channelIndex',outputCol='affiliate_channelVec')\n",
    "affiliate_provider_encoder = OneHotEncoder(inputCol='affiliate_providerIndex',outputCol='affiliate_providerVec')\n",
    "first_affiliate_tracked_encoder = OneHotEncoder(inputCol='first_affiliate_trackedIndex',outputCol='first_affiliate_trackedVec')\n",
    "signup_app_encoder = OneHotEncoder(inputCol='signup_appIndex',outputCol='signup_appVec')\n",
    "first_device_encoder = OneHotEncoder(inputCol='first_deviceIndex',outputCol='first_deviceVec')\n",
    "first_browser_encoder = OneHotEncoder(inputCol='first_browserIndex',outputCol='first_browserVec')\n",
    "\n",
    "# And finally, using vector assembler to turn all of these columns into one column (named features).\n",
    "assembler = VectorAssembler(inputCols=['genderVec','signup_methodVec','languageVec','affiliate_channelVec',\n",
    "                                       'affiliate_providerVec','first_affiliate_trackedVec','signup_appVec','first_deviceVec','first_browserVec',\n",
    "                                       'age','signup_flow', 'sum(secs_elapsed)'], outputCol=\"features\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Then go through our steps. It's essentially sequential to the above.\n",
    "pipeline = Pipeline(stages=[gender_indexer, signup_method_indexer, language_indexer, affiliate_channel_indexer,\n",
    "                            affiliate_provider_indexer, first_affiliate_tracked_indexer, signup_app_indexer, first_device_type_indexer,\n",
    "                            first_browser_indexer,country_destination_indexer,gender_encoder,signup_method_encoder,language_encoder,\n",
    "                            affiliate_channel_encoder,affiliate_provider_encoder,first_affiliate_tracked_encoder,signup_app_encoder,\n",
    "                            first_device_encoder,first_browser_encoder, assembler])\n",
    "\n",
    "# Now that we've got a number of steps, let's apply it to the DataFrame.\n",
    "pipeline_model = pipeline.fit(new_train)\n",
    "\n",
    "# Incorporate results into a new DataFrame.\n",
    "pipe_df = pipeline_model.transform(new_train)\n",
    "\n",
    "# Remove all variables other than features and label. \n",
    "pipe_df = pipe_df.select('label', 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Split our data. Note that the new DataFrame is being used.\n",
    "train_data, test_data = pipe_df.randomSplit([0.7,0.3])\n",
    "print(\"Training Dataset Count: \" + str(train_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))\n",
    "\n",
    "# Instantiate the model.\n",
    "lr_model = LogisticRegression(featuresCol='features',labelCol='label')\n",
    "\n",
    "# Fit the model.\n",
    "lr_model = lr_model.fit(train_data)\n",
    "\n",
    "# And evaluate the model using the test data.\n",
    "results = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Visualising the coefficients. Sort from lowest to highest.\n",
    "beta = np.sort(lr_model.coefficients)\n",
    "\n",
    "# Plot the data.\n",
    "plt.plot(beta)\n",
    "\n",
    "# Add a label to the data.\n",
    "plt.ylabel('Beta Coefficients')\n",
    "\n",
    "# Show the graph. \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get a summary of the data.\n",
    "training_summary = lr_model.summary\n",
    "\n",
    "# Convert the DataFrame to a Pandas DataFrame.\n",
    "ROC = training_summary.roc.toPandas()\n",
    "\n",
    "# Plot the true positive and false positive rates.\n",
    "plt.plot(ROC['FPR'],ROC['TPR'])\n",
    "\n",
    "# Define the labels.\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Print the AUC statistic. \n",
    "print('Area Under the Curve: ' + str(training_summary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to Pandas DataFrame.\n",
    "pr = training_summary.pr.toPandas()\n",
    "\n",
    "# Plot model recall and precision.\n",
    "plt.plot(pr['recall'],pr['precision'])\n",
    "\n",
    "# Define the labels and show the graph. \n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "categoricalColumns = ['gender','signup_method','language','affiliate_channel','affiliate_provider','first_affiliate_tracked','signup_app','first_device_type','first_browser']\n",
    "stages = []\n",
    "inputCols=[]\n",
    "outputCols=[]\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "label_stringIdx = StringIndexer(inputCol = 'country_destination', outputCol = 'label')\n",
    "stages += [label_stringIdx]\n",
    "numericCols = ['age', 'signup_flow', 'sum(secs_elapsed)']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "dataset = spark.createDataFrame(\n",
    "    [(7, \"US\", 18, 1.0),\n",
    "     (8, \"CA\", 12, 0.0),\n",
    "     (9, \"NZ\", 15, 0.0)],\n",
    "    [\"id\", \"country\", \"hour\", \"clicked\"])\n",
    "\n",
    "formula = RFormula(\n",
    "    formula=\"clicked ~ country + hour\",\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\")\n",
    "\n",
    "output = formula.fit(new_train).transform(new_train)\n",
    "output.select(\"features\", \"label\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
